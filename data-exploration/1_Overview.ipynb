{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 't' from 'sqlalchemy_utils' (/Users/clemens/.pyenv/versions/3.7.0/envs/heckoverflow/lib/python3.7/site-packages/sqlalchemy_utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-852e767e3776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 't' from 'sqlalchemy_utils' (/Users/clemens/.pyenv/versions/3.7.0/envs/heckoverflow/lib/python3.7/site-packages/sqlalchemy_utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "from sqlalchemy_utils import analyze\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from scipy.stats import expon\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "postgres_str = ('postgresql://localhost/crossvalidated')\n",
    "cnx = create_engine(postgres_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<p>I want to fit a function $f(x_1,x_2..)$ to (noisy) data with unknown variance. For each datapoint, I have a weight $w_i$ which is proportional to the reliability of that particular datapoint. The real uncertainty of the datapoints is unknown.\\nI do the fitting using Matlab and Levenberg-Marquardt so that I end up with the parameter estimates $\\\\hat{\\\\beta}$ and the Jacobian $J$. I calculate the variance of the parameter estimates as follows:\\n$$\\\\hat{\\\\sigma}^2=\\\\frac{RSS}{n-p+1} \\\\cdot (J'WJ)^{-1}$$ \\nWhere $W$ is the diagonal matrix of the weights, $n$ is the number of datapoints and $p$ is the degrees of freedom.</p>\\n\\n<p>My question is regarding the normalization of the weights and it's effect on the parameter uncertainty, since I have seen some conflicting definitions and opinions on this subject.</p>\\n\\n<p><strong>Question</strong>: How do I normalize my weights so that the calculated parameter standard errors are meaningful?\\nI currently normalize the weights so that their sum is the number of datapoints $N$, similar to non-weighted least squares: $\\\\Sigma w_i = N$. Is this correct?</p>\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.read_sql_query('''SELECT body FROM Posts LIMIT 5;''', cnx)\n",
    "tmp.body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nested Loop', 'Index Scan', 'Index Scan']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis = analyze(cnx, sqlalchemy.sql.text('SELECT Q.Id as question_id, A.Id as answer_id, A.OwnerUserId as answerer_user_id         FROM Posts A INNER JOIN Posts Q on A.ParentId = Q.Id         WHERE A.ParentId IN (23, 44) AND (Q.AcceptedAnswerId = A.Id OR A.Score >= 3)'))\n",
    "analysis.node_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Various measures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_per_year = pd.read_sql_query(\n",
    "                    '''SELECT CAST(date_part('year', CreationDate) AS INTEGER) AS Year, COUNT(*) AS Post_n\n",
    "                    FROM Posts\n",
    "                    GROUP BY date_part('year', CreationDate);''', cnx)\n",
    "sns.lineplot(x=posts_per_year['year'], y=posts_per_year['post_n']).set_title('Posts per year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_per_year = pd.read_sql_query(\n",
    "                    '''SELECT CAST(date_part('year', CreationDate) AS INTEGER) AS Year, COUNT(*) AS qst_n\n",
    "                    FROM Posts\n",
    "                    WHERE PostTypeId=1\n",
    "                    GROUP BY date_part('year', CreationDate);''', cnx)\n",
    "sns.lineplot(x=questions_per_year['year'], y=questions_per_year['qst_n']).set_title('Questions per year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newusers_per_year = pd.read_sql_query(\n",
    "                    '''SELECT CAST(date_part('year', CreationDate) AS INTEGER) AS Year, COUNT(*) AS User_n\n",
    "                    FROM Users\n",
    "                    GROUP BY date_part('year', CreationDate);''', cnx)\n",
    "sns.lineplot(x=newusers_per_year['year'], y=newusers_per_year['user_n']).set_title('New users per year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ans_per_year = pd.read_sql_query(\n",
    "        '''SELECT Year, AVG(c_answers) AS Avg_answers FROM (\n",
    "        SELECT Q.Id, CAST(date_part('year', Q.CreationDate) AS INTEGER) AS Year, COUNT(Ans.Id) AS c_answers\n",
    "        FROM Posts AS Q LEFT JOIN Posts AS Ans ON Q.Id=Ans.ParentId\n",
    "        WHERE Q.PostTypeId=1\n",
    "        GROUP BY Q.Id) AS anstable\n",
    "        GROUP BY Year\n",
    "        ORDER BY Year ASC;''', cnx)\n",
    "sns.lineplot(x=avg_ans_per_year['year'], y=avg_ans_per_year['avg_answers']).set_title('Average number of answers to a question per year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of users that wrote more than x answers:\")\n",
    "for i in [1,2,5,10]:\n",
    "    avg_ans_per_year = pd.read_sql_query(\n",
    "            '''with countPerUser as (Select OwnerUserId, count(OwnerUserId) as c from Posts where ParentId is not null group by OwnerUserId)\n",
    "    Select (Select CAST(Count(c) AS float) from countPerUser where c>%i)/CAST(Count(c) AS float) from countPerUser'''%i, cnx)\n",
    "    print(\"Users with more than \", i, \" answers: \", avg_ans_per_year.values[0,0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of users that wrote more than x questions:\")\n",
    "for i in [1,2,5,10]:\n",
    "    avg_ans_per_year = pd.read_sql_query(\n",
    "            '''with countPerUser as (Select OwnerUserId, count(OwnerUserId) as c from Posts where ParentId is null group by OwnerUserId)\n",
    "    Select (Select CAST(Count(c) AS float) from countPerUser where c>%i)/CAST(Count(c) AS float) from countPerUser'''%i, cnx)\n",
    "    print(\"Users with more than \", i, \" question: \", avg_ans_per_year.values[0,0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_acc_ans = pd.read_sql_query(\n",
    "        '''SELECT Q.Id, Q.CreationDate, (Ans.CreationDate - Q.CreationDate) AS TimeToAns\n",
    "        FROM Posts AS Q LEFT JOIN Posts AS Ans ON Q.AcceptedAnswerId=Ans.Id\n",
    "        WHERE Q.PostTypeId=1;''', cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_acc_ans['timetoans_bin'] = 'never'\n",
    "time_to_acc_ans.loc[time_to_acc_ans['timetoans'] <= pd.Timedelta('1 hour'), 'timetoans_bin'] = '<1 hour'\n",
    "time_to_acc_ans.loc[\n",
    "    (time_to_acc_ans['timetoans'] > pd.Timedelta('1 hour')) & (time_to_acc_ans['timetoans'] <= pd.Timedelta('1 day')),\n",
    "    'timetoans_bin'] = '<1 day'\n",
    "time_to_acc_ans.loc[\n",
    "    (time_to_acc_ans['timetoans'] > pd.Timedelta('1 day')) & (time_to_acc_ans['timetoans'] <= pd.Timedelta('7 days')),\n",
    "    'timetoans_bin'] = '<1 week'\n",
    "time_to_acc_ans.loc[\n",
    "    (time_to_acc_ans['timetoans'] > pd.Timedelta('7 days')) & (time_to_acc_ans['timetoans'] <= pd.Timedelta('30 days')),\n",
    "    'timetoans_bin'] = '<1 month'\n",
    "time_to_acc_ans.loc[\n",
    "    (time_to_acc_ans['timetoans'] > pd.Timedelta('30 days')) & (time_to_acc_ans['timetoans'] <= pd.Timedelta('365 days')),\n",
    "    'timetoans_bin'] = '<1 year'\n",
    "time_to_acc_ans.loc[time_to_acc_ans['timetoans'] > pd.Timedelta('365 days'), 'timetoans_bin'] = '>1 year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"timetoans_bin\", data=time_to_acc_ans, order=['<1 hour', '<1 day', '<1 week', '<1 month', '<1 year', '>1 year', 'never']).set_title('Time to accepted answer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_first_ans = pd.read_sql_query(\n",
    "        '''SELECT Q.Id, Q.CreationDate, MIN(Ans.CreationDate - Q.CreationDate) AS TimeToAns\n",
    "        FROM Posts AS Q LEFT JOIN Posts AS Ans ON Q.Id=Ans.ParentId\n",
    "        WHERE Q.PostTypeId=1\n",
    "        GROUP BY Q.Id;''', cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_first_ans['timetoans_bin'] = 'never'\n",
    "time_to_first_ans.loc[time_to_first_ans['timetoans'] <= pd.Timedelta('1 hour'), 'timetoans_bin'] = '<1 hour'\n",
    "time_to_first_ans.loc[\n",
    "    (time_to_first_ans['timetoans'] > pd.Timedelta('1 hour')) & (time_to_first_ans['timetoans'] <= pd.Timedelta('1 day')),\n",
    "    'timetoans_bin'] = '<1 day'\n",
    "time_to_first_ans.loc[\n",
    "    (time_to_first_ans['timetoans'] > pd.Timedelta('1 day')) & (time_to_first_ans['timetoans'] <= pd.Timedelta('7 days')),\n",
    "    'timetoans_bin'] = '<1 week'\n",
    "time_to_first_ans.loc[\n",
    "    (time_to_first_ans['timetoans'] > pd.Timedelta('7 days')) & (time_to_first_ans['timetoans'] <= pd.Timedelta('30 days')),\n",
    "    'timetoans_bin'] = '<1 month'\n",
    "time_to_first_ans.loc[\n",
    "    (time_to_first_ans['timetoans'] > pd.Timedelta('30 days')) & (time_to_first_ans['timetoans'] <= pd.Timedelta('365 days')),\n",
    "    'timetoans_bin'] = '<1 year'\n",
    "time_to_first_ans.loc[time_to_first_ans['timetoans'] > pd.Timedelta('365 days'), 'timetoans_bin'] = '>1 year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"timetoans_bin\", data=time_to_first_ans, order=['<1 hour', '<1 day', '<1 week', '<1 month', '<1 year', '>1 year', 'never']).set_title('Time to first answer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_first_ans.groupby(['creationyear', 'timetoans_bin']).size().reset_index()\\\n",
    "    .pivot(index='timetoans_bin', columns='creationyear', values=0)\\\n",
    "    .reindex(['<1 hour', '<1 day', '<1 week', '<1 month', '<1 year', '>1 year', 'never']).T\\\n",
    "    .plot(kind='bar', stacked=True).set_title('Time to first answer over the years')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time between first answer and accepted Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time first answer to accepted answer Q.Id, Q.CreationDate, MIN(Ans.CreationDate - Q.CreationDate) AS TimeToAns\n",
    "q = '''SELECT Q.Id as qid, Accepted_Ans.CreationDate - MIN(Ans.CreationDate) as first_ans_to_accepted_ans, EXTRACT(YEAR FROM Q.CreationDate) as creationyear\n",
    "        FROM Posts AS Q INNER JOIN Posts AS Ans ON Q.Id=Ans.ParentId\n",
    "        LEFT JOIN Posts AS Accepted_Ans on Q.AcceptedAnswerId = Accepted_Ans.Id\n",
    "        WHERE Q.PostTypeId=1 GROUP BY Q.Id, Accepted_Ans.CreationDate\n",
    "        '''\n",
    "first_to_accepted_answer = pd.read_sql_query(q, cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_df_with_timebins(df, colname):\n",
    "    bin_col_name = \"{}_bin\".format(colname)\n",
    "    \n",
    "    df[bin_col_name] = 'never'\n",
    "    df.loc[df[colname] == pd.Timedelta(0), bin_col_name] = 'same'\n",
    "    df.loc[(df[colname] <= pd.Timedelta('1 hour')) & (df[colname] != pd.Timedelta(0)),\n",
    "           bin_col_name] = '<1 hour'\n",
    "    df.loc[\n",
    "        (df[colname] > pd.Timedelta('1 hour')) & (df[colname] <= pd.Timedelta('1 day')),\n",
    "        bin_col_name] = '<1 day'\n",
    "    df.loc[\n",
    "        (df[colname] > pd.Timedelta('1 day')) & (df[colname] <= pd.Timedelta('7 days')),\n",
    "        bin_col_name] = '<1 week'\n",
    "    df.loc[\n",
    "        (df[colname] > pd.Timedelta('7 days')) & (df[colname] <= pd.Timedelta('30 days')),\n",
    "        bin_col_name] = '<1 month'\n",
    "    df.loc[\n",
    "        (df[colname] > pd.Timedelta('30 days')) & (df[colname] <= pd.Timedelta('365 days')),\n",
    "        bin_col_name] = '<1 year'\n",
    "    df.loc[df[colname] > pd.Timedelta('365 days'), bin_col_name] = '>1 year'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_to_accepted_with_bins = extend_df_with_timebins(first_to_accepted_answer, \"first_ans_to_accepted_ans\")\n",
    "#first_to_accepted_with_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.countplot(x=\"first_ans_to_accepted_ans_bin\", \n",
    "              data=first_to_accepted_with_bins, \n",
    "              order=['same', '<1 hour', '<1 day', '<1 week', '<1 month', '<1 year', '>1 year', 'never']).set_title('Time from first answer to accepted answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_to_accepted_with_bins.groupby(['creationyear', 'first_ans_to_accepted_ans_bin']).size().reset_index()\\\n",
    "    .pivot(index='first_ans_to_accepted_ans_bin', columns='creationyear', values=0)\\\n",
    "    .reindex(['same', '<1 hour', '<1 day', '<1 week', '<1 month', '<1 year', '>1 year', 'never']).T\\\n",
    "    .plot(kind='bar', stacked=True, figsize=(10,8.27)).set_title('Time to first answer over the years')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Users Age when they answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "    SELECT A.ParentId as question_id, U.Id as answerer_id, COALESCE(A.Id = Q.AcceptedAnswerId, FALSE) accepted, A.CreationDate as date_of_answer, (A.CreationDate - Q.CreationDate) as age_of_question, A.CreationDate - U.CreationDate as user_age_at_answer_time\n",
    "    FROM Posts A INNER JOIN Users U ON A.OwnerUserId = U.Id \n",
    "    INNER JOIN Posts Q ON A.ParentId = Q.Id\n",
    "    WHERE A.PostTypeId = 2 \n",
    "\"\"\"\n",
    "\n",
    "user_age_at_answer_times = pd.read_sql_query(q, cnx)\n",
    "\n",
    "# can be negative since some answers have a time in the database dump that is obviously wrong\n",
    "# https://data.stackexchange.com/stats/query/1137375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_age_at_answer_times[user_age_at_answer_times.user_age_at_answer_time > pd.Timedelta(0)].sort_values(\"user_age_at_answer_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_age_in_days = user_age_at_answer_times.user_age_at_answer_time / pd.Timedelta('1 day')\n",
    "question_age_in_days = user_age_at_answer_times.age_of_question / pd.Timedelta('1 day')\n",
    "\n",
    "user_age_accepted = user_age_in_days[user_age_at_answer_times.accepted]\n",
    "user_age_not_accepted = user_age_in_days[np.invert(user_age_at_answer_times.accepted)]\n",
    "\n",
    "_ = plt.hist([user_age_accepted, user_age_not_accepted], bins=np.linspace(0, 3200, 30), label=['accepted', 'not_accepted'], log=True)\n",
    "plt.xlabel(\"Age at answer time in days\")\n",
    "plt.ylabel(\"Count [log]\")\n",
    "plt.legend()\n",
    "# plt.scatter(x=question_age_in_days, y=user_age_in_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze which tags are occuring most often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_sql_query(\n",
    "        '''SELECT Tags FROM Posts''', cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_posts = len(tags)\n",
    "none_counter = 0\n",
    "tag_list = []\n",
    "for t in tags.values:\n",
    "    if t[0] is not None:\n",
    "        tags_this_post = t[0].split(\"><\")\n",
    "        for tag in tags_this_post:\n",
    "            tag = tag.replace(\"<\", \"\")\n",
    "            tag = tag.replace(\">\", \"\")\n",
    "            tag_list.append(tag)\n",
    "    else:\n",
    "        none_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tag_list))\n",
    "unique_tags, counts = np.unique(tag_list, return_counts=True)\n",
    "sorted_counts_inds = np.argsort(counts)\n",
    "sorted_tags = unique_tags[sorted_counts_inds]\n",
    "sorted_counts = counts[sorted_counts_inds]\n",
    "print(sorted_tags[-10:], sorted_counts[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted_tags[-10:]\n",
    "data = sorted_counts[-10:]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(np.arange(1,11,1), data)\n",
    "plt.xticks(np.arange(1,11,1), labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further information about tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NUMBER OF DIFFERENT TAGS:\", len(unique_tags))\n",
    "print(\"PERCENTAGE OF TAGS OCCURING MORE THAN ONCE: \", 100*len(unique_tags[counts>1])/len(unique_tags), \"%\")\n",
    "print(\"PERCENTAGE OF TAGS OCCURING MORE THAN 100 TIMES: \", 100*len(unique_tags[counts>100])/len(unique_tags), \"%\")\n",
    "print(\"PERCENTAGE OF POSTS WITHOUT ANY TAGS:\", 100*none_counter/number_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to fit distribution to question_creation - answer values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all questionage values (for each answer, get how old the corresponding question was when it was answered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>questionage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>257</td>\n",
       "      <td>0.004560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.003495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>0.004954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32669</td>\n",
       "      <td>0.394907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.021169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>0.021586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>114</td>\n",
       "      <td>0.002350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>114</td>\n",
       "      <td>0.002442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>146</td>\n",
       "      <td>0.006458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>155</td>\n",
       "      <td>0.005914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>155</td>\n",
       "      <td>0.020613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>146</td>\n",
       "      <td>0.065035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>220</td>\n",
       "      <td>0.008843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>726</td>\n",
       "      <td>0.099028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>47</td>\n",
       "      <td>0.701701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>257</td>\n",
       "      <td>0.008345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>257</td>\n",
       "      <td>0.010023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>47</td>\n",
       "      <td>0.642292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50</td>\n",
       "      <td>0.699988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>278</td>\n",
       "      <td>0.062535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>290</td>\n",
       "      <td>0.086528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>220</td>\n",
       "      <td>0.391979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>257</td>\n",
       "      <td>0.230440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>114</td>\n",
       "      <td>0.763981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>114</td>\n",
       "      <td>0.798183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>114</td>\n",
       "      <td>0.799479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>114</td>\n",
       "      <td>0.800116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>257</td>\n",
       "      <td>0.642627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>373</td>\n",
       "      <td>0.052002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>373</td>\n",
       "      <td>0.058032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143794</th>\n",
       "      <td>423542</td>\n",
       "      <td>0.802720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143795</th>\n",
       "      <td>423639</td>\n",
       "      <td>0.015208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143796</th>\n",
       "      <td>423062</td>\n",
       "      <td>4.810671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143797</th>\n",
       "      <td>423537</td>\n",
       "      <td>1.497153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143798</th>\n",
       "      <td>423678</td>\n",
       "      <td>0.009537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143799</th>\n",
       "      <td>423678</td>\n",
       "      <td>0.010706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143800</th>\n",
       "      <td>414574</td>\n",
       "      <td>62.276100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143801</th>\n",
       "      <td>423504</td>\n",
       "      <td>2.226088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143802</th>\n",
       "      <td>423837</td>\n",
       "      <td>0.158449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143803</th>\n",
       "      <td>423867</td>\n",
       "      <td>0.169375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143804</th>\n",
       "      <td>178492</td>\n",
       "      <td>1403.148148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143805</th>\n",
       "      <td>423699</td>\n",
       "      <td>1.683345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143806</th>\n",
       "      <td>423941</td>\n",
       "      <td>0.123785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143807</th>\n",
       "      <td>424021</td>\n",
       "      <td>0.172743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143808</th>\n",
       "      <td>424052</td>\n",
       "      <td>0.072882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143809</th>\n",
       "      <td>421952</td>\n",
       "      <td>15.692211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143810</th>\n",
       "      <td>424096</td>\n",
       "      <td>0.010972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143811</th>\n",
       "      <td>422431</td>\n",
       "      <td>13.117801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143812</th>\n",
       "      <td>424120</td>\n",
       "      <td>0.099190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143813</th>\n",
       "      <td>424056</td>\n",
       "      <td>0.675683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143814</th>\n",
       "      <td>424180</td>\n",
       "      <td>0.302697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143815</th>\n",
       "      <td>424263</td>\n",
       "      <td>0.072315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143816</th>\n",
       "      <td>424291</td>\n",
       "      <td>0.019225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143817</th>\n",
       "      <td>424300</td>\n",
       "      <td>0.042500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143818</th>\n",
       "      <td>422370</td>\n",
       "      <td>15.310822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143819</th>\n",
       "      <td>424338</td>\n",
       "      <td>0.131644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143820</th>\n",
       "      <td>424429</td>\n",
       "      <td>0.029687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143821</th>\n",
       "      <td>424425</td>\n",
       "      <td>0.129572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143822</th>\n",
       "      <td>424435</td>\n",
       "      <td>0.322292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143823</th>\n",
       "      <td>422422</td>\n",
       "      <td>15.783333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143824 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  questionage\n",
       "0          257     0.004560\n",
       "1           50     0.003495\n",
       "2           47     0.004954\n",
       "3        32669     0.394907\n",
       "4           50     0.021169\n",
       "5           50     0.021586\n",
       "6          114     0.002350\n",
       "7          114     0.002442\n",
       "8          146     0.006458\n",
       "9          155     0.005914\n",
       "10         155     0.020613\n",
       "11         146     0.065035\n",
       "12         220     0.008843\n",
       "13         726     0.099028\n",
       "14          47     0.701701\n",
       "15         257     0.008345\n",
       "16         257     0.010023\n",
       "17          47     0.642292\n",
       "18          50     0.699988\n",
       "19         278     0.062535\n",
       "20         290     0.086528\n",
       "21         220     0.391979\n",
       "22         257     0.230440\n",
       "23         114     0.763981\n",
       "24         114     0.798183\n",
       "25         114     0.799479\n",
       "26         114     0.800116\n",
       "27         257     0.642627\n",
       "28         373     0.052002\n",
       "29         373     0.058032\n",
       "...        ...          ...\n",
       "143794  423542     0.802720\n",
       "143795  423639     0.015208\n",
       "143796  423062     4.810671\n",
       "143797  423537     1.497153\n",
       "143798  423678     0.009537\n",
       "143799  423678     0.010706\n",
       "143800  414574    62.276100\n",
       "143801  423504     2.226088\n",
       "143802  423837     0.158449\n",
       "143803  423867     0.169375\n",
       "143804  178492  1403.148148\n",
       "143805  423699     1.683345\n",
       "143806  423941     0.123785\n",
       "143807  424021     0.172743\n",
       "143808  424052     0.072882\n",
       "143809  421952    15.692211\n",
       "143810  424096     0.010972\n",
       "143811  422431    13.117801\n",
       "143812  424120     0.099190\n",
       "143813  424056     0.675683\n",
       "143814  424180     0.302697\n",
       "143815  424263     0.072315\n",
       "143816  424291     0.019225\n",
       "143817  424300     0.042500\n",
       "143818  422370    15.310822\n",
       "143819  424338     0.131644\n",
       "143820  424429     0.029687\n",
       "143821  424425     0.129572\n",
       "143822  424435     0.322292\n",
       "143823  422422    15.783333\n",
       "\n",
       "[143824 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionage_table = pd.read_sql_query('''SELECT a.id, (answercreationdate-CreationDate) as questionage FROM \n",
    "(SELECT parentid as Id, creationdate as answercreationdate FROM Posts WHERE PostTypeId=2) a\n",
    "LEFT JOIN Posts b ON a.Id=b.Id;''', cnx) # On AS Q LEFT JOIN Posts AS Ans\n",
    "questionage_table[\"questionage\"] = questionage_table[\"questionage\"].dt.days +  (questionage_table[\"questionage\"].dt.seconds)/(24*60*60)\n",
    "questionage_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('''(SELECT parentid as Id, creationdate as answercreationdate FROM Posts WHERE PostTypeId=2 LIMIT 5);''', cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_vals = questionage_table[\"questionage\"].values\n",
    "age_vals = age_vals[age_vals>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(age_vals[age_vals<10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit scipy distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = st.gilbrat.fit(age_vals[age_vals<500].astype(np.float64))\n",
    "print(params)\n",
    "plt.plot(x, eval(dist).pdf(x, params[0], params[1]),'r-', lw=5, alpha=0.6, label=dist, c=cols[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"green\", \"red\", \"purple\", \"yellow\"]\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(age_vals[age_vals<100], bins=50, density=True)\n",
    "for i, dist in enumerate([\"st.expon\", \"st.pareto\", \"st.powerlaw\", \"st.gilbrat\"]):\n",
    "    params = eval(dist).fit(age_vals[age_vals<100].astype(np.float64))\n",
    "    print(params)\n",
    "    if dist == \"st.gilbrat\":\n",
    "        params = (-0.3530395997092245, 1.3032193696909253)\n",
    "    x = np.linspace(0, 100, 100)\n",
    "    # plt.plot(x, st.gilbrat.pdf(x, params[0], params[1]),'r-', lw=5, alpha=0.6, label='expon pdf')\n",
    "    if len(params)==2:\n",
    "        plt.plot(x, eval(dist).pdf(x, params[0], params[1]),'r-', lw=5, alpha=0.6, label=dist, c=cols[i])\n",
    "    elif len(params)==3:\n",
    "        plt.plot(x, eval(dist).pdf(x, params[0], params[1], params[2]),'r-', lw=5, alpha=0.6, label=dist, c=cols[i])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to iterate through all distributions (did not work for me, copied from stackoverflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import statsmodels as sm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# Create models from data\n",
    "def best_fit_distribution(data, bins=200, ax=None):\n",
    "    \"\"\"Model data by finding best fit distribution to data\"\"\"\n",
    "    # Get histogram of original data\n",
    "    y, x = np.histogram(data, bins=bins, density=True)\n",
    "    x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "\n",
    "    # Distributions to check\n",
    "    DISTRIBUTIONS = [        \n",
    "        st.alpha,st.anglit,st.arcsine,st.beta,st.betaprime,st.bradford,st.burr,st.cauchy,st.chi,st.chi2,st.cosine,\n",
    "        st.dgamma,st.dweibull,st.erlang,st.expon,st.exponnorm,st.exponweib,st.exponpow,st.f,st.fatiguelife,st.fisk,\n",
    "        st.foldcauchy,st.foldnorm,st.frechet_r,st.frechet_l,st.genlogistic,st.genpareto,st.gennorm,st.genexpon,\n",
    "        st.genextreme,st.gausshyper,st.gamma,st.gengamma,st.genhalflogistic,st.gilbrat,st.gompertz,st.gumbel_r,\n",
    "        st.gumbel_l,st.halfcauchy,st.halflogistic,st.halfnorm,st.halfgennorm,st.hypsecant,st.invgamma,st.invgauss,\n",
    "        st.invweibull,st.johnsonsb,st.johnsonsu,st.ksone,st.kstwobign,st.laplace,st.levy,st.levy_l,st.levy_stable,\n",
    "        st.logistic,st.loggamma,st.loglaplace,st.lognorm,st.lomax,st.maxwell,st.mielke,st.nakagami,st.ncx2,st.ncf,\n",
    "        st.nct,st.norm,st.pareto,st.pearson3,st.powerlaw,st.powerlognorm,st.powernorm,st.rdist,st.reciprocal,\n",
    "        st.rayleigh,st.rice,st.recipinvgauss,st.semicircular,st.t,st.triang,st.truncexpon,st.truncnorm,st.tukeylambda,\n",
    "        st.uniform,st.vonmises,st.vonmises_line,st.wald,st.weibull_min,st.weibull_max,st.wrapcauchy\n",
    "    ]\n",
    "\n",
    "    # Best holders\n",
    "    best_distribution = st.norm\n",
    "    best_params = (0.0, 1.0)\n",
    "    best_sse = np.inf\n",
    "\n",
    "    # Estimate distribution parameters from data\n",
    "    for distribution in DISTRIBUTIONS:\n",
    "\n",
    "            # fit dist to data\n",
    "        params = distribution.fit(data)\n",
    "\n",
    "        # Separate parts of parameters\n",
    "        arg = params[:-2]\n",
    "        loc = params[-2]\n",
    "        scale = params[-1]\n",
    "\n",
    "        # Calculate fitted PDF and error with fit in distribution\n",
    "        pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n",
    "        sse = np.sum(np.power(y - pdf, 2.0))\n",
    "\n",
    "        # if axis pass in add to plot\n",
    "        try:\n",
    "            if ax:\n",
    "                pd.Series(pdf, x).plot(ax=ax)\n",
    "            end\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # identify if this distribution is better\n",
    "        if best_sse > sse > 0:\n",
    "            best_distribution = distribution\n",
    "            best_params = params\n",
    "            best_sse = sse\n",
    "            print(best_params)\n",
    "\n",
    "    return (best_distribution.name, best_params)\n",
    "\n",
    "def make_pdf(dist, params, size=10000):\n",
    "    \"\"\"Generate distributions's Probability Distribution Function \"\"\"\n",
    "\n",
    "    # Separate parts of parameters\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "\n",
    "    # Get sane start and end points of distribution\n",
    "    start = dist.ppf(0.01, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.01, loc=loc, scale=scale)\n",
    "    end = dist.ppf(0.99, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.99, loc=loc, scale=scale)\n",
    "\n",
    "    # Build PDF and turn into pandas Series\n",
    "    x = np.linspace(start, end, size)\n",
    "    y = dist.pdf(x, loc=loc, scale=scale, *arg)\n",
    "    pdf = pd.Series(y, x)\n",
    "\n",
    "    return pdf\n",
    "\n",
    "# Load data from statsmodels datasets\n",
    "data = age_vals\n",
    "\n",
    "# Plot for comparison\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = plt.hist(data, bins=50)\n",
    "# Save plot limits\n",
    "\n",
    "# Find best fit distribution\n",
    "best_fit_name, best_fit_params = best_fit_distribution(data, 200, ax)\n",
    "best_dist = getattr(st, best_fit_name)\n",
    "\n",
    "print(best_dist, best_fit_params)\n",
    "# Make PDF with best params \n",
    "pdf = make_pdf(best_dist, best_fit_params)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = pdf.plot(lw=2, label='PDF', legend=True)\n",
    "# data.plot(kind='hist', bins=50, normed=True, alpha=0.5, label='Data', legend=True, ax=ax)\n",
    "plt.hist(data, bins=50)\n",
    "\n",
    "param_names = (best_dist.shapes + ', loc, scale').split(', ') if best_dist.shapes else ['loc', 'scale']\n",
    "param_str = ', '.join(['{}={:0.2f}'.format(k,v) for k,v in zip(param_names, best_fit_params)])\n",
    "dist_str = '{}({})'.format(best_fit_name, param_str)\n",
    "\n",
    "ax.set_title(u'El Niño sea temp. with best fit distribution \\n' + dist_str)\n",
    "ax.set_xlabel(u'Temp. (°C)')\n",
    "ax.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get question age value (for all answered questions)\n",
    "questionage_table = pd.read_sql_query('''SELECT a.id, (answercreationdate-CreationDate) as questionage FROM \n",
    "(SELECT parentid as Id, creationdate as answercreationdate FROM Posts WHERE PostTypeId=2) a\n",
    "LEFT JOIN Posts b ON a.Id=b.Id;''', cnx) # On AS Q LEFT JOIN Posts AS Ans\n",
    "questionage_table[\"questionage\"] = questionage_table[\"questionage\"].dt.days +  (questionage_table[\"questionage\"].dt.seconds)/(24*60*60)\n",
    "age_vals = questionage_table[\"questionage\"].values\n",
    "age_vals = age_vals[age_vals>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# build cdf\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = age_vals[age_vals<100]\n",
    "hist, bins = np.histogram(data, bins=500)\n",
    "\n",
    "bin_midpoints = bins[1:] # + np.diff(bins)/2\n",
    "cdf = np.cumsum(hist)\n",
    "cdf = cdf / cdf[-1]\n",
    "values = np.random.rand(100)\n",
    "value_bins = np.searchsorted(cdf, values)\n",
    "random_from_cdf = bin_midpoints[value_bins]\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.hist(data, 50)\n",
    "plt.subplot(122)\n",
    "plt.hist(random_from_cdf, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample some test data from gilbrat (these are then the age values of the open questions)\n",
    "import scipy.stats as st\n",
    "rans = np.asarray(sorted(st.gilbrat.rvs(-0.3530395997092245, 1.3032193696909253, size=1000)))\n",
    "rans = rans[rans>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_vals = rans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my sampling scheme:\n",
    "sample_size=100\n",
    "uni, counts = np.unique(random_from_cdf, return_counts=True)\n",
    "val_before = 0\n",
    "final_list = []\n",
    "for r in range(len(uni)):\n",
    "    val = uni[r]\n",
    "    val_set = set(np.where(age_vals<val)[0]).intersection(np.where(age_vals>val_before)[0])\n",
    "    print(val, val_set)\n",
    "    val_before=val\n",
    "    if len(val_set)>0:\n",
    "        subset = np.random.choice(list(val_set), counts[r], replace=False)\n",
    "        print(subset)\n",
    "    final_list.extend(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
